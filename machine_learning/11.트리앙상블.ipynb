{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44705de",
   "metadata": {},
   "source": [
    "# 앙상블 \n",
    "\n",
    "- 여러 머신러닝 모델을 결합하여 더 좋은 모델을 얻는 방법 \n",
    "- 앙상블의 종류\n",
    "\n",
    "    1. 보팅(Voting)\n",
    "        - 여러 개의 분류기가 투표를 통해 최종 예측 결과를 결정 \n",
    "        - 종류\n",
    "            - 하드 보팅 (Hard Voting)\n",
    "                - 다수의 분류기가 예측한 결과값을 최종 결과로 선정 (다수결)\n",
    "            - 소프트 보팅 (Soft Voting)\n",
    "                - 모든 분류기가 예측한 결정 확률의 평균이 가장 높은 결과값을 최종 결과로 선정 \n",
    "                - 목소리가 큰 것의 손을 들어줌.\n",
    "                - --> 얘가 좀 더 성능이 잘 나오는 경향\n",
    "                \n",
    "    <img src = 'voting.png'>\n",
    "    \n",
    "    <br><br>\n",
    "    \n",
    "    2. 배깅(Bagging)\n",
    "        - 데이터 샘플링(Bootstrap)을 통해 모델을 학습시키고 결과를 집계하는 방법 \n",
    "            - Bootstrap 방식이란 \n",
    "                - 데이터가 조금씩은 편향되도록 샘플링하는 기법 (복원 추출)\n",
    "                - 분산이 높은 모델의 과대적합 위험을 줄이는 효과가 있음. (의사결정나무의 단점 보완)\n",
    "                    - 일부러 편향을 다양하게 시켜 그것들을 합치기 때문에\n",
    "        - 모두 같은 유형의 알고리즘 기반의 분류기 사용해야 함.\n",
    "            - 보통 의사결정트리 모델을 백개 쯤 합침 --> RandomForest\n",
    "        - 데이터 분할 시 중복 허용 (복원 추출)\n",
    "        - 예시) 랜덤포레스트(RandomForest)\n",
    "            - 과대적합되기 쉬운 의사결정나무의 과대적합을 줄여 성능을 높일 수 있음. \n",
    "            - 의사결정나무 모델에서 쓰이는 메소드들을 쓸 수 있음. \n",
    "                \n",
    "    <img src = 'bagging.png'>\n",
    "    \n",
    "    <br><br>\n",
    "    \n",
    "    3. 부스팅(Boosting)\n",
    "        - 여러 개의 분류기가 \"순차적으로\" 학습 수행\n",
    "        - 이전 분류기의 예측이 틀린 데이터에 대해 올바르게 예측할 수 있도록 다음 분류기에게 가중치(weight)를 부여하며 학습과 예측 진행 \n",
    "        - 계속하여 분류기에게 가중치를 부스팅하며 학습을 진행하기 때문에 \"부스팅 방식\"이라고 불림. \n",
    "        - 일반적으로 부스팅 방식이 배깅 방식에 비해 성능이 좋지만 속도가 느리고 과적합이 발생할 가능성이 더 높음 \n",
    "        - 예시 : XGBoost, LightGBM\n",
    "        \n",
    "        <img src = \"boosting.png\">\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d430ce2",
   "metadata": {},
   "source": [
    "- 첫번째가 잘맞추는 영역, 두번째가 잘맞추는 영역 ... 다 합침 \n",
    "\n",
    "- 배깅과 부스팅의 차이\n",
    "    - 부스팅은 순서대로 학습되어야 함. (직렬 연결) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d90969d",
   "metadata": {},
   "source": [
    "# 랜덤포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d5a31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_validate # 교차검증 \n",
    "from sklearn.ensemble import (RandomForestClassifier, \n",
    "                              GradientBoostingClassifier, \n",
    "                              ExtraTreesClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "253263c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>sugar</th>\n",
       "      <th>pH</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  sugar    pH  class\n",
       "0      9.4    1.9  3.51    0.0\n",
       "1      9.8    2.6  3.20    0.0\n",
       "2      9.8    2.3  3.26    0.0\n",
       "3      9.8    1.9  3.16    0.0\n",
       "4      9.4    1.9  3.51    0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wine.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc764a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5197, 3), (1300, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df[['alcohol', 'sugar', 'pH']]\n",
    "y = df['class']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   stratify=y,\n",
    "                                                   random_state=4)\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72020530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본적으로 100개 결정트리 사용\n",
    "# 100개 동시 학습 가능 (병렬적 학습)\n",
    "rf = RandomForestClassifier(\n",
    "            random_state=4,\n",
    "            n_jobs=-1) # 동시 몇개까지 학습시킬건지 (최대치로)\n",
    "            # cpu 감당할 수 있는데까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17cc5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계산만 하는거지 학습시키는 건 아님 \n",
    "scores = cross_validate(rf, \n",
    "                        x_train, \n",
    "                        y_train, \n",
    "                        return_train_score=True, \n",
    "                        # 원래는 테스트셋에 대해서만 결과 반환 \n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dea948",
   "metadata": {},
   "source": [
    "- k겹 교차 검증 생각하면 됨. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2524fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.28568006, 0.28618741, 0.28568006, 0.38924003, 0.39125991]),\n",
       " 'score_time': array([0.1229105 , 0.10940433, 0.1229105 , 0.10827279, 0.10827279]),\n",
       " 'test_score': array([0.87980769, 0.89326923, 0.89124158, 0.88161694, 0.90086622]),\n",
       " 'train_score': array([0.99783498, 0.99807554, 0.9978355 , 0.9978355 , 0.997114  ])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542aac64",
   "metadata": {},
   "source": [
    "- fit_time: 다섯 모델에 대한 훈련 시간 \n",
    "- score_time: 테스트 데이터에 대해 추론하는 시간\n",
    "- test_score: 테스트 데이터에 대한 점수\n",
    "- train_score: 훈련 데이터에 대한 점수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b1f506e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997739101034747 0.8893603316798696\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeae398",
   "metadata": {},
   "source": [
    "- 랜덤포레스트는 의사결정나무의 앙상블이기 때문에 의사결정나무에서 제공하는 주요 매개변수는 모두 사용 가능 \n",
    "    - criterion, max_depth 등 \n",
    "    - 특성 중요도 계산도 가능 \n",
    "        - 랜덤포레스트의 특성 중요도는 각 의사결정나무의 특성 중요도 취합 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffddc204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b8d72ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23910783 0.49363618 0.26725599]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102a30e6",
   "metadata": {},
   "source": [
    "- 그냥 의사결정나무 하나만 사용했을 때보다 sugar 특성의 중요도가 낮아짐 (<-- 0.6)\n",
    "- alcohol과 pH 특성의 중요도는 상승함. --> \"일반화 성능이 상승함\" \n",
    "- --> bagging 때문임. \n",
    "    - 일부로 조금조금 편향되게 골라냈기 때문에 \n",
    "    - sugar 사용하지 않고도 red wine, white wine 분류하는 법을 배운 것 \n",
    "    - 랜덤 포레스트는 하나의 특성에 과도하게 집중되지 않고 더 많은 특성이 훈련에 기여할 기회를 얻음.\n",
    "    - 과대적합이 줄어들고 일반화 성능을 높일 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc9b61c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(oob_score=True,\n",
    "                           n_jobs=-1,\n",
    "                           random_state=4)\n",
    "\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3149746e",
   "metadata": {},
   "source": [
    "- out-of-bag score (oob_score) \n",
    "    - 복원 추출해서 뽑는데 (bootstrap) 이렇게 나무 100개 만들어낸다 하더라도,\n",
    "    - 일부 데이터는 한번도 선택되지 않았을 수 있음 --> \"out-of-bag\" 샘플 \n",
    "    - 이 친구들 또한 test data 와 다름 없는 애들이 됨. \n",
    "    - 일반화 성능을 측정하는데 하나의 지표가 될 수 있음. \n",
    "        - 데이터가 적은 상황에서 train/test 나누지도 못할 상황에서 사용 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c8d883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8982105060611891\n"
     ]
    }
   ],
   "source": [
    "print(rf.oob_score_) \n",
    "# cross_validate 한 점수와 비슷"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefc8587",
   "metadata": {},
   "source": [
    "# 엑스트라 트리 \n",
    "\n",
    "- 랜덤 포레스트와 매우 유사 \n",
    "    - 기본적으로 100개의 의사결정나무 훈련\n",
    "    - 의사결정나무가 제공하는 대부분의 매개변수 지원\n",
    "    \n",
    "- 랜덤 포레스트와의 차이점\n",
    "    - 부트스트랩 샘플을 사용하지 않음.\n",
    "        - 전체 훈련세트 사용 \n",
    "    - 노드를 분할할 때 가장 좋은 분할을 찾는 게 아니라 무작위로 분할 \n",
    "        - 하나의 의사결정나무에서 특성을 무작위로 분할한다면 성능이 낮아지겠지만\n",
    "        - 많은 트리를 앙상블하기 때문에 과대적합을 방지하고 검증세트 점수를 높이는 효과가 나타남.\n",
    "        - (+) 계산속도가 더 빠름. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbdc0e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997739101034747 0.8889738654031243\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_jobs=-1, random_state=4)\n",
    "scores = cross_validate(et, x_train, y_train, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729732f0",
   "metadata": {},
   "source": [
    "- 효과 볼려면 나무 수 많거나, 더 자세히 학습을 해야함.\n",
    "- 완전 기본 상태의 엑스트라 트리는 성능 자체는 보통 좀더 떨어짐. \n",
    "- 예제에서는 독립변수가 많지 않아서 랜덤포레스트와의 차이가 크지 않음.\n",
    "- 일반적으로 엑스트라 트리가 무작위성이 더 크기 때문에 랜덤포레스트보다 더 많은 트리를 훈련해야함. \n",
    "- 하지만 랜덤하게 노드를 분할하기 때문에 계산속도는 더 빠름. \n",
    "    - 정확도는 비슷하더라도 시간은 더 벌 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7ca6a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20237273, 0.5168859 , 0.28074137])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 엑스트라 트리도 특성 중요도 제공 \n",
    "et.fit(x_train, y_train)\n",
    "\n",
    "et.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892047d3",
   "metadata": {},
   "source": [
    "- 하나의 의사결정나무 보다는 일반화 성능이 더 좋음. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44a4db",
   "metadata": {},
   "source": [
    "# 그래디언트 부스팅\n",
    "\n",
    "- 깊이가 얕은 결정트리를 사용하여 이전 트리의 오차를 보완하는 방식으로 앙상블하는 기법 \n",
    "- 사이킷런의 GradientBoostingClassifier는 기본적으로 깊이가 3인 결정트리를 100개 사용 \n",
    "    - 깊이가 얕은 결정트리를 사용하여 과대적합을 방지할 수 있고 높은 일반화 성능을 기대 가능 \n",
    "- 앞의 모델의 오차 예측하여, 예측값 수정. 또 그전까지의 모델의 결과의 오차를 예측... 이렇게 오차를 줄여나가는 모델 계속.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f95e820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8852225474789824 0.8666561782779298\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state=4) # 부스팅에는 n_jobs 존재 불가\n",
    "# 병렬적으로 연산이 불가능하고, 무조건 직렬 이기 때문 !! \n",
    "scores = cross_validate(gb, x_train, y_train, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3043a4",
   "metadata": {},
   "source": [
    "- 그래디언트 부스팅은 결정트리의 개수 늘려도 과대적합에 강함.\n",
    "- 원래 그냥 부스팅은 과대적합의 위험이 있지만, GradientBoosting은 강함.\n",
    "    - 깊이 얕은 결정트리를 여러개 사용해서\n",
    "    - 더 많이 이어붙여도 과대적합 발생 가능성 적음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8502e2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9437655707561889 0.8712747094099356\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state=4,\n",
    "                               n_estimators=500, # 트리 개수 더 많이\n",
    "                               learning_rate=0.2) # 오차 예측한 걸 얼마나 반영해서 고쳐나갈 것인가 \n",
    "                                # 디폴트는 0.1\n",
    "scores = cross_validate(gb, x_train, y_train, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05bed168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16530862, 0.67028501, 0.16440637])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.fit(x_train, y_train)\n",
    "gb.feature_importances_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
